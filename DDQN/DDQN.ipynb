{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from env_current import *\n",
    "from collections import deque\n",
    "from utils import *\n",
    "from qnetwork import *\n",
    "import plotting\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, env, qnet):\n",
    "    \n",
    "    global EXPLORATION_RATE\n",
    "  \n",
    "    summary_ops, summary_vars = build_summaries()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(SUMMARY_DIR, sess.graph)\n",
    "    \n",
    "    qnet.update_target()\n",
    "    \n",
    "    replay_buffer = ReplayBuffer(BUFFER_SIZE, RANDOM_SEED)\n",
    "    \n",
    "    reward_list = []\n",
    "    \n",
    "    for num_epi in range(MAX_EPISODES):\n",
    "\n",
    "        s = env.reset()\n",
    "        s = [list(np.unravel_index(s, env.shape))]\n",
    "\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "\n",
    "        for j in range(MAX_EPISODE_LEN):\n",
    "\n",
    "            a = np.argmax(qnet.predict_q(np.reshape(s, (1, qnet.state_dim))))\n",
    "    \n",
    "            if np.random.rand(1) < EXPLORATION_RATE:\n",
    "                s2, r, terminal, info = env.step(np.random.randint(0,qnet.action_dim))\n",
    "            else:\n",
    "                s2, r, terminal, info = env.step(a)\n",
    "            \n",
    "            s2 = list(np.unravel_index(s2, env.shape))\n",
    "\n",
    "            replay_buffer.add(np.reshape(s, (qnet.state_dim,)), np.reshape(a, (1,)), r,\n",
    "                              terminal, np.reshape(s2, (qnet.state_dim,)))\n",
    "\n",
    "            # Keep adding experience to the memory until\n",
    "            # there are at least minibatch size samples\n",
    "            if replay_buffer.size() > MINIBATCH_SIZE:\n",
    "                s_batch, a_batch, r_batch, t_batch, s2_batch = replay_buffer.sample_batch(MINIBATCH_SIZE)\n",
    "\n",
    "                # Calculate targets\n",
    "                target_q = qnet.predect_target(s2_batch)\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(MINIBATCH_SIZE):\n",
    "                    if t_batch[k]:\n",
    "                        y_i.append(r_batch[k])\n",
    "                    else:\n",
    "                        y_i.append(r_batch[k] + GAMMA * np.amax(target_q[k]))\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                predicted_q_value, _ = qnet.train(s_batch, a_batch, np.reshape(y_i, (MINIBATCH_SIZE, 1)), num_epi)\n",
    "\n",
    "                ep_ave_max_q += np.amax(predicted_q_value)\n",
    "                \n",
    "                # Update target networks\n",
    "                qnet.update_target()\n",
    "\n",
    "            s = s2\n",
    "            ep_reward += r\n",
    "\n",
    "            if terminal or j == MAX_EPISODE_LEN-1:\n",
    "                \n",
    "                if EXPLORATION_RATE > 0.02 and terminal:\n",
    "                    EXPLORATION_RATE = EXPLORATION_RATE*0.92\n",
    "                \n",
    "                reward_list += [ep_reward]\n",
    "                \n",
    "                if np.average(reward_list[-10:]) >= LR_DECAY_TRUNCATION:\n",
    "                    qnet.decay_learning_rate(1)\n",
    "\n",
    "                summary_str = sess.run(summary_ops, feed_dict={\n",
    "                    summary_vars[0]: ep_reward,\n",
    "                    summary_vars[1]: ep_ave_max_q / float(j),\n",
    "                    summary_vars[2]: EXPLORATION_RATE,\n",
    "                    summary_vars[3]: qnet.get_learning_rate()\n",
    "                })\n",
    "\n",
    "                writer.add_summary(summary_str, num_epi)\n",
    "                writer.flush()\n",
    "\n",
    "                print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f} | Exploration: {:.6f} '.format(int(ep_reward), \\\n",
    "                        num_epi, (ep_ave_max_q / float(j)), EXPLORATION_RATE))\n",
    "                \n",
    "                f = open(\"stats.txt\", \"ab\")\n",
    "                f.write(\"| Reward: \" + str(int(ep_reward)) \n",
    "                        +\" | Episode: \" + str(num_epi) \n",
    "                        + \" | Qmax: \" + str(ep_ave_max_q / float(j)) \n",
    "                        + \" | Exploration: \" + str(EXPLORATION_RATE) + \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                break\n",
    "                \n",
    "        if num_epi%1 == 0:\n",
    "            state_list = []\n",
    "            action_list = []\n",
    "            world = np.zeros(env.shape)\n",
    "            for state in range(env.nS):\n",
    "                state = np.unravel_index(state, env.shape)\n",
    "                action = qnet.predict_q(np.reshape(state, (1,state_dim)))\n",
    "                action = np.argmax(action)\n",
    "                state_list.append(state)\n",
    "                action_list.append(action)\n",
    "                \n",
    "#             print np.reshape(action_list, env.shape)\n",
    "                \n",
    "            f = open(\"action.txt\",\"ab\")\n",
    "            np.savetxt(f, np.reshape(action_list, env.shape), fmt=\"%i\")\n",
    "            f.write(\"---------------------------\\n\")\n",
    "            f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0015\n",
    "GAMMA = 0.99\n",
    "# GAMMA = 0.7\n",
    "TAU = 0.001\n",
    "BUFFER_SIZE = 10**6\n",
    "MINIBATCH_SIZE = 64\n",
    "RANDOM_SEED = 101\n",
    "MAX_EPISODES = 50000\n",
    "MAX_EPISODE_LEN = 1500\n",
    "file_appendix = time.ctime()[4:16].replace(\"  \",\"\").replace(\" \",\"_\").replace(\":\",\"-\")\n",
    "SUMMARY_DIR = './results/tf_ddqn_' + file_appendix\n",
    "SAVE_DIR = \"./saved_model/\" + file_appendix + \"/ddqn.ckpt\"\n",
    "EXPLORATION_RATE = 0.65\n",
    "LR_DECAY_TRUNCATION = -50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDQN Saved\n",
      "| Reward: -1500 | Episode: 0 | Qmax: 29.0392 | Exploration: 0.650000 \n",
      "| Reward: -1500 | Episode: 1 | Qmax: 31.8888 | Exploration: 0.650000 \n",
      "| Reward: -1500 | Episode: 2 | Qmax: 29.5829 | Exploration: 0.650000 \n",
      "| Reward: -1500 | Episode: 3 | Qmax: 27.3973 | Exploration: 0.650000 \n",
      "| Reward: -1500 | Episode: 4 | Qmax: 25.8825 | Exploration: 0.650000 \n",
      "| Reward: -492 | Episode: 5 | Qmax: 30.2546 | Exploration: 0.598000 \n",
      "| Reward: -345 | Episode: 6 | Qmax: 32.7059 | Exploration: 0.550160 \n",
      "| Reward: -84 | Episode: 7 | Qmax: 33.3009 | Exploration: 0.506147 \n",
      "| Reward: -44 | Episode: 8 | Qmax: 34.2149 | Exploration: 0.465655 \n",
      "| Reward: -58 | Episode: 9 | Qmax: 33.6918 | Exploration: 0.428403 \n",
      "| Reward: -61 | Episode: 10 | Qmax: 33.5526 | Exploration: 0.394131 \n",
      "| Reward: -101 | Episode: 11 | Qmax: 34.2039 | Exploration: 0.362600 \n",
      "| Reward: -977 | Episode: 12 | Qmax: 31.9958 | Exploration: 0.333592 \n",
      "| Reward: -179 | Episode: 13 | Qmax: 30.5665 | Exploration: 0.306905 \n",
      "| Reward: -408 | Episode: 14 | Qmax: 31.6914 | Exploration: 0.282352 \n",
      "| Reward: -78 | Episode: 15 | Qmax: 33.7087 | Exploration: 0.259764 \n",
      "| Reward: -1283 | Episode: 16 | Qmax: 31.5243 | Exploration: 0.238983 \n",
      "| Reward: -222 | Episode: 17 | Qmax: 30.0685 | Exploration: 0.219864 \n",
      "| Reward: -1500 | Episode: 18 | Qmax: 28.2605 | Exploration: 0.219864 \n",
      "| Reward: -175 | Episode: 19 | Qmax: 26.9225 | Exploration: 0.202275 \n",
      "DDQN Saved\n",
      "| Reward: -1026 | Episode: 20 | Qmax: 25.9264 | Exploration: 0.186093 \n",
      "| Reward: -1500 | Episode: 21 | Qmax: 23.8273 | Exploration: 0.186093 \n",
      "| Reward: -1500 | Episode: 22 | Qmax: 21.4331 | Exploration: 0.186093 \n",
      "| Reward: -1500 | Episode: 23 | Qmax: 19.0219 | Exploration: 0.186093 \n",
      "| Reward: -1500 | Episode: 24 | Qmax: 16.8283 | Exploration: 0.186093 \n",
      "| Reward: -175 | Episode: 25 | Qmax: 15.9212 | Exploration: 0.171206 \n",
      "| Reward: -336 | Episode: 26 | Qmax: 15.5205 | Exploration: 0.157509 \n",
      "| Reward: -318 | Episode: 27 | Qmax: 15.0043 | Exploration: 0.144909 \n",
      "| Reward: -1500 | Episode: 28 | Qmax: 13.6956 | Exploration: 0.144909 \n",
      "| Reward: -416 | Episode: 29 | Qmax: 12.4026 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 30 | Qmax: 11.1241 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 31 | Qmax: 9.2722 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 32 | Qmax: 7.5718 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 33 | Qmax: 6.5332 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 34 | Qmax: 5.1501 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 35 | Qmax: 3.5421 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 36 | Qmax: 1.8565 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 37 | Qmax: 0.2061 | Exploration: 0.133316 \n",
      "| Reward: -1500 | Episode: 38 | Qmax: -1.1291 | Exploration: 0.133316 \n",
      "| Reward: -426 | Episode: 39 | Qmax: -1.8300 | Exploration: 0.122651 \n",
      "DDQN Saved\n",
      "| Reward: -234 | Episode: 40 | Qmax: -2.0973 | Exploration: 0.112839 \n",
      "| Reward: -49 | Episode: 41 | Qmax: -2.2302 | Exploration: 0.103812 \n",
      "| Reward: -685 | Episode: 42 | Qmax: -2.5405 | Exploration: 0.095507 \n",
      "| Reward: -702 | Episode: 43 | Qmax: -3.0786 | Exploration: 0.087866 \n",
      "| Reward: -139 | Episode: 44 | Qmax: -3.4855 | Exploration: 0.080837 \n",
      "| Reward: -305 | Episode: 45 | Qmax: -3.5239 | Exploration: 0.074370 \n",
      "| Reward: -198 | Episode: 46 | Qmax: -3.6559 | Exploration: 0.068420 \n",
      "| Reward: -446 | Episode: 47 | Qmax: -3.8605 | Exploration: 0.062947 \n",
      "| Reward: -405 | Episode: 48 | Qmax: -4.1376 | Exploration: 0.057911 \n",
      "| Reward: -196 | Episode: 49 | Qmax: -4.3335 | Exploration: 0.053278 \n",
      "| Reward: -191 | Episode: 50 | Qmax: -4.5259 | Exploration: 0.049016 \n",
      "| Reward: -474 | Episode: 51 | Qmax: -4.6328 | Exploration: 0.045095 \n",
      "| Reward: -98 | Episode: 52 | Qmax: -4.9144 | Exploration: 0.041487 \n",
      "| Reward: -91 | Episode: 53 | Qmax: -4.9719 | Exploration: 0.038168 \n",
      "| Reward: -136 | Episode: 54 | Qmax: -5.0535 | Exploration: 0.035115 \n",
      "| Reward: -382 | Episode: 55 | Qmax: -5.1570 | Exploration: 0.032305 \n",
      "| Reward: -281 | Episode: 56 | Qmax: -5.4313 | Exploration: 0.029721 \n",
      "| Reward: -30 | Episode: 57 | Qmax: -5.7960 | Exploration: 0.027343 \n",
      "| Reward: -261 | Episode: 58 | Qmax: -5.6622 | Exploration: 0.025156 \n",
      "| Reward: -46 | Episode: 59 | Qmax: -5.9269 | Exploration: 0.023143 \n",
      "DDQN Saved\n",
      "| Reward: -264 | Episode: 60 | Qmax: -5.8048 | Exploration: 0.021292 \n",
      "| Reward: -362 | Episode: 61 | Qmax: -6.0374 | Exploration: 0.019589 \n",
      "| Reward: -248 | Episode: 62 | Qmax: -6.2538 | Exploration: 0.019589 \n",
      "| Reward: -163 | Episode: 63 | Qmax: -6.1508 | Exploration: 0.019589 \n",
      "| Reward: -267 | Episode: 64 | Qmax: -6.2151 | Exploration: 0.019589 \n",
      "| Reward: -826 | Episode: 65 | Qmax: -6.5516 | Exploration: 0.019589 \n",
      "| Reward: -157 | Episode: 66 | Qmax: -6.7249 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 67 | Qmax: -7.1097 | Exploration: 0.019589 \n",
      "| Reward: -382 | Episode: 68 | Qmax: -6.9661 | Exploration: 0.019589 \n",
      "| Reward: -197 | Episode: 69 | Qmax: -7.2324 | Exploration: 0.019589 \n",
      "| Reward: -144 | Episode: 70 | Qmax: -7.3449 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 71 | Qmax: -7.5587 | Exploration: 0.019589 \n",
      "| Reward: -159 | Episode: 72 | Qmax: -7.3457 | Exploration: 0.019589 \n",
      "| Reward: -156 | Episode: 73 | Qmax: -7.4789 | Exploration: 0.019589 \n",
      "| Reward: -497 | Episode: 74 | Qmax: -7.5479 | Exploration: 0.019589 \n",
      "| Reward: -369 | Episode: 75 | Qmax: -7.6920 | Exploration: 0.019589 \n",
      "| Reward: -249 | Episode: 76 | Qmax: -7.9076 | Exploration: 0.019589 \n",
      "| Reward: -193 | Episode: 77 | Qmax: -8.0402 | Exploration: 0.019589 \n",
      "| Reward: -74 | Episode: 78 | Qmax: -7.9630 | Exploration: 0.019589 \n",
      "| Reward: -244 | Episode: 79 | Qmax: -8.0381 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -17 | Episode: 80 | Qmax: -8.6144 | Exploration: 0.019589 \n",
      "| Reward: -99 | Episode: 81 | Qmax: -8.1323 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 82 | Qmax: -8.3480 | Exploration: 0.019589 \n",
      "| Reward: -34 | Episode: 83 | Qmax: -8.2804 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 84 | Qmax: -8.4591 | Exploration: 0.019589 \n",
      "| Reward: -63 | Episode: 85 | Qmax: -8.2052 | Exploration: 0.019589 \n",
      "| Reward: -81 | Episode: 86 | Qmax: -8.1554 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 87 | Qmax: -8.3890 | Exploration: 0.019589 \n",
      "| Reward: -54 | Episode: 88 | Qmax: -8.2444 | Exploration: 0.019589 \n",
      "| Reward: -324 | Episode: 89 | Qmax: -8.1380 | Exploration: 0.019589 \n",
      "| Reward: -51 | Episode: 90 | Qmax: -8.5398 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 91 | Qmax: -8.8783 | Exploration: 0.019589 \n",
      "| Reward: -64 | Episode: 92 | Qmax: -8.4354 | Exploration: 0.019589 \n",
      "| Reward: -49 | Episode: 93 | Qmax: -8.3419 | Exploration: 0.019589 \n",
      "| Reward: -37 | Episode: 94 | Qmax: -8.2917 | Exploration: 0.019589 \n",
      "| Reward: -106 | Episode: 95 | Qmax: -8.1842 | Exploration: 0.019589 \n",
      "| Reward: -43 | Episode: 96 | Qmax: -8.1935 | Exploration: 0.019589 \n",
      "| Reward: -63 | Episode: 97 | Qmax: -8.0809 | Exploration: 0.019589 \n",
      "| Reward: -101 | Episode: 98 | Qmax: -7.9846 | Exploration: 0.019589 \n",
      "| Reward: -112 | Episode: 99 | Qmax: -7.9330 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -19 | Episode: 100 | Qmax: -8.3516 | Exploration: 0.019589 \n",
      "| Reward: -36 | Episode: 101 | Qmax: -8.2146 | Exploration: 0.019589 \n",
      "| Reward: -137 | Episode: 102 | Qmax: -8.0467 | Exploration: 0.019589 \n",
      "| Reward: -231 | Episode: 103 | Qmax: -8.2149 | Exploration: 0.019589 \n",
      "| Reward: -33 | Episode: 104 | Qmax: -8.5345 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 105 | Qmax: -8.7589 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 106 | Qmax: -8.6696 | Exploration: 0.019589 \n",
      "| Reward: -45 | Episode: 107 | Qmax: -8.5797 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 108 | Qmax: -9.0455 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 109 | Qmax: -8.7240 | Exploration: 0.019589 \n",
      "| Reward: -107 | Episode: 110 | Qmax: -8.5091 | Exploration: 0.019589 \n",
      "| Reward: -59 | Episode: 111 | Qmax: -8.4122 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 112 | Qmax: -8.7374 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 113 | Qmax: -8.7858 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 114 | Qmax: -8.6999 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 115 | Qmax: -8.7033 | Exploration: 0.019589 \n",
      "| Reward: -107 | Episode: 116 | Qmax: -8.1626 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -33 | Episode: 117 | Qmax: -8.2554 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 118 | Qmax: -8.4879 | Exploration: 0.019589 \n",
      "| Reward: -59 | Episode: 119 | Qmax: -8.2034 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -41 | Episode: 120 | Qmax: -7.9746 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 121 | Qmax: -8.1008 | Exploration: 0.019589 \n",
      "| Reward: -130 | Episode: 122 | Qmax: -7.6693 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 123 | Qmax: -7.9116 | Exploration: 0.019589 \n",
      "| Reward: -78 | Episode: 124 | Qmax: -7.4221 | Exploration: 0.019589 \n",
      "| Reward: -59 | Episode: 125 | Qmax: -7.6174 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 126 | Qmax: -7.9071 | Exploration: 0.019589 \n",
      "| Reward: -185 | Episode: 127 | Qmax: -7.5433 | Exploration: 0.019589 \n",
      "| Reward: -71 | Episode: 128 | Qmax: -7.7057 | Exploration: 0.019589 \n",
      "| Reward: -58 | Episode: 129 | Qmax: -7.7672 | Exploration: 0.019589 \n",
      "| Reward: -180 | Episode: 130 | Qmax: -7.7652 | Exploration: 0.019589 \n",
      "| Reward: -37 | Episode: 131 | Qmax: -7.8596 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 132 | Qmax: -7.8046 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 133 | Qmax: -7.9085 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 134 | Qmax: -7.8268 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 135 | Qmax: -8.0928 | Exploration: 0.019589 \n",
      "| Reward: -76 | Episode: 136 | Qmax: -7.6958 | Exploration: 0.019589 \n",
      "| Reward: -44 | Episode: 137 | Qmax: -7.7372 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 138 | Qmax: -7.9269 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 139 | Qmax: -8.0396 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -17 | Episode: 140 | Qmax: -8.0067 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 141 | Qmax: -8.0418 | Exploration: 0.019589 \n",
      "| Reward: -37 | Episode: 142 | Qmax: -7.8486 | Exploration: 0.019589 \n",
      "| Reward: -123 | Episode: 143 | Qmax: -7.6948 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 144 | Qmax: -8.0365 | Exploration: 0.019589 \n",
      "| Reward: -103 | Episode: 145 | Qmax: -7.7517 | Exploration: 0.019589 \n",
      "| Reward: -38 | Episode: 146 | Qmax: -7.8959 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 147 | Qmax: -8.2643 | Exploration: 0.019589 \n",
      "| Reward: -208 | Episode: 148 | Qmax: -7.9671 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 149 | Qmax: -8.6069 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 150 | Qmax: -8.4901 | Exploration: 0.019589 \n",
      "| Reward: -86 | Episode: 151 | Qmax: -8.1433 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 152 | Qmax: -8.5725 | Exploration: 0.019589 \n",
      "| Reward: -38 | Episode: 153 | Qmax: -8.2116 | Exploration: 0.019589 \n",
      "| Reward: -83 | Episode: 154 | Qmax: -8.1628 | Exploration: 0.019589 \n",
      "| Reward: -39 | Episode: 155 | Qmax: -8.3697 | Exploration: 0.019589 \n",
      "| Reward: -88 | Episode: 156 | Qmax: -8.3410 | Exploration: 0.019589 \n",
      "| Reward: -56 | Episode: 157 | Qmax: -8.4940 | Exploration: 0.019589 \n",
      "| Reward: -26 | Episode: 158 | Qmax: -8.6290 | Exploration: 0.019589 \n",
      "| Reward: -176 | Episode: 159 | Qmax: -8.3536 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -90 | Episode: 160 | Qmax: -8.3310 | Exploration: 0.019589 \n",
      "| Reward: -46 | Episode: 161 | Qmax: -8.5051 | Exploration: 0.019589 \n",
      "| Reward: -116 | Episode: 162 | Qmax: -8.3359 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 163 | Qmax: -8.7928 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 164 | Qmax: -8.8306 | Exploration: 0.019589 \n",
      "| Reward: -67 | Episode: 165 | Qmax: -8.3234 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 166 | Qmax: -8.5639 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 167 | Qmax: -8.8257 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 168 | Qmax: -8.6577 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 169 | Qmax: -8.4620 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 170 | Qmax: -8.3623 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 171 | Qmax: -8.5384 | Exploration: 0.019589 \n",
      "| Reward: -80 | Episode: 172 | Qmax: -8.2604 | Exploration: 0.019589 \n",
      "| Reward: -107 | Episode: 173 | Qmax: -8.2772 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 174 | Qmax: -8.5441 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 175 | Qmax: -8.5110 | Exploration: 0.019589 \n",
      "| Reward: -306 | Episode: 176 | Qmax: -8.1584 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 177 | Qmax: -8.4159 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 178 | Qmax: -8.5879 | Exploration: 0.019589 \n",
      "| Reward: -116 | Episode: 179 | Qmax: -8.1003 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 180 | Qmax: -8.5908 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 181 | Qmax: -8.3593 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 182 | Qmax: -8.4295 | Exploration: 0.019589 \n",
      "| Reward: -76 | Episode: 183 | Qmax: -7.9932 | Exploration: 0.019589 \n",
      "| Reward: -36 | Episode: 184 | Qmax: -8.0506 | Exploration: 0.019589 \n",
      "| Reward: -59 | Episode: 185 | Qmax: -7.7371 | Exploration: 0.019589 \n",
      "| Reward: -98 | Episode: 186 | Qmax: -7.7126 | Exploration: 0.019589 \n",
      "| Reward: -105 | Episode: 187 | Qmax: -7.6700 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 188 | Qmax: -8.0398 | Exploration: 0.019589 \n",
      "| Reward: -53 | Episode: 189 | Qmax: -7.7919 | Exploration: 0.019589 \n",
      "| Reward: -33 | Episode: 190 | Qmax: -7.9035 | Exploration: 0.019589 \n",
      "| Reward: -78 | Episode: 191 | Qmax: -7.7723 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 192 | Qmax: -8.2483 | Exploration: 0.019589 \n",
      "| Reward: -53 | Episode: 193 | Qmax: -7.8700 | Exploration: 0.019589 \n",
      "| Reward: -121 | Episode: 194 | Qmax: -7.7761 | Exploration: 0.019589 \n",
      "| Reward: -74 | Episode: 195 | Qmax: -8.0393 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 196 | Qmax: -8.4069 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 197 | Qmax: -8.3534 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 198 | Qmax: -8.5001 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 199 | Qmax: -8.2526 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -49 | Episode: 200 | Qmax: -8.1341 | Exploration: 0.019589 \n",
      "| Reward: -92 | Episode: 201 | Qmax: -8.0864 | Exploration: 0.019589 \n",
      "| Reward: -79 | Episode: 202 | Qmax: -8.0911 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 203 | Qmax: -8.5069 | Exploration: 0.019589 \n",
      "| Reward: -47 | Episode: 204 | Qmax: -7.9825 | Exploration: 0.019589 \n",
      "| Reward: -28 | Episode: 205 | Qmax: -8.1747 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 206 | Qmax: -8.0724 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 207 | Qmax: -8.0681 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 208 | Qmax: -8.1439 | Exploration: 0.019589 \n",
      "| Reward: -96 | Episode: 209 | Qmax: -7.4115 | Exploration: 0.019589 \n",
      "| Reward: -37 | Episode: 210 | Qmax: -7.5233 | Exploration: 0.019589 \n",
      "| Reward: -75 | Episode: 211 | Qmax: -7.5151 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 212 | Qmax: -7.8220 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 213 | Qmax: -7.7115 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 214 | Qmax: -7.8700 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 215 | Qmax: -7.8154 | Exploration: 0.019589 \n",
      "| Reward: -71 | Episode: 216 | Qmax: -7.4401 | Exploration: 0.019589 \n",
      "| Reward: -43 | Episode: 217 | Qmax: -7.4333 | Exploration: 0.019589 \n",
      "| Reward: -69 | Episode: 218 | Qmax: -7.4135 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 219 | Qmax: -7.6915 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -21 | Episode: 220 | Qmax: -7.7416 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 221 | Qmax: -7.7367 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 222 | Qmax: -7.8590 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 223 | Qmax: -7.7773 | Exploration: 0.019589 \n",
      "| Reward: -81 | Episode: 224 | Qmax: -7.4476 | Exploration: 0.019589 \n",
      "| Reward: -56 | Episode: 225 | Qmax: -7.5508 | Exploration: 0.019589 \n",
      "| Reward: -37 | Episode: 226 | Qmax: -7.5340 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 227 | Qmax: -7.8019 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 228 | Qmax: -7.7830 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 229 | Qmax: -7.6522 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 230 | Qmax: -7.8818 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 231 | Qmax: -7.8711 | Exploration: 0.019589 \n",
      "| Reward: -90 | Episode: 232 | Qmax: -7.4933 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -76 | Episode: 233 | Qmax: -7.5115 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 234 | Qmax: -7.8792 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 235 | Qmax: -7.7979 | Exploration: 0.019589 \n",
      "| Reward: -79 | Episode: 236 | Qmax: -7.7105 | Exploration: 0.019589 \n",
      "| Reward: -57 | Episode: 237 | Qmax: -7.8963 | Exploration: 0.019589 \n",
      "| Reward: -36 | Episode: 238 | Qmax: -7.9109 | Exploration: 0.019589 \n",
      "| Reward: -30 | Episode: 239 | Qmax: -7.8181 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -23 | Episode: 240 | Qmax: -7.9924 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 241 | Qmax: -8.2853 | Exploration: 0.019589 \n",
      "| Reward: -53 | Episode: 242 | Qmax: -7.8848 | Exploration: 0.019589 \n",
      "| Reward: -53 | Episode: 243 | Qmax: -7.9476 | Exploration: 0.019589 \n",
      "| Reward: -103 | Episode: 244 | Qmax: -7.8879 | Exploration: 0.019589 \n",
      "| Reward: -59 | Episode: 245 | Qmax: -8.1029 | Exploration: 0.019589 \n",
      "| Reward: -33 | Episode: 246 | Qmax: -8.2333 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 247 | Qmax: -8.4071 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 248 | Qmax: -8.4677 | Exploration: 0.019589 \n",
      "| Reward: -131 | Episode: 249 | Qmax: -8.1320 | Exploration: 0.019589 \n",
      "| Reward: -49 | Episode: 250 | Qmax: -8.3973 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 251 | Qmax: -8.7184 | Exploration: 0.019589 \n",
      "| Reward: -36 | Episode: 252 | Qmax: -8.5465 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 253 | Qmax: -8.9431 | Exploration: 0.019589 \n",
      "| Reward: -129 | Episode: 254 | Qmax: -8.3522 | Exploration: 0.019589 \n",
      "| Reward: -47 | Episode: 255 | Qmax: -8.3201 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 256 | Qmax: -8.8265 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 257 | Qmax: -8.7168 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 258 | Qmax: -8.7792 | Exploration: 0.019589 \n",
      "| Reward: -55 | Episode: 259 | Qmax: -8.2845 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -45 | Episode: 260 | Qmax: -8.2557 | Exploration: 0.019589 \n",
      "| Reward: -39 | Episode: 261 | Qmax: -8.3796 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 262 | Qmax: -8.7095 | Exploration: 0.019589 \n",
      "| Reward: -30 | Episode: 263 | Qmax: -8.5090 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 264 | Qmax: -8.7191 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 265 | Qmax: -8.4521 | Exploration: 0.019589 \n",
      "| Reward: -116 | Episode: 266 | Qmax: -8.1465 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 267 | Qmax: -8.3546 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 268 | Qmax: -8.2861 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 269 | Qmax: -8.5658 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 270 | Qmax: -8.4087 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 271 | Qmax: -8.3380 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 272 | Qmax: -8.2283 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 273 | Qmax: -7.8700 | Exploration: 0.019589 \n",
      "| Reward: -78 | Episode: 274 | Qmax: -7.5906 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 275 | Qmax: -7.9805 | Exploration: 0.019589 \n",
      "| Reward: -39 | Episode: 276 | Qmax: -7.6018 | Exploration: 0.019589 \n",
      "| Reward: -43 | Episode: 277 | Qmax: -7.7183 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 278 | Qmax: -8.1140 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 279 | Qmax: -7.8856 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 280 | Qmax: -7.8895 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 281 | Qmax: -8.0277 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 282 | Qmax: -8.0514 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 283 | Qmax: -7.7352 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 284 | Qmax: -8.0608 | Exploration: 0.019589 \n",
      "| Reward: -46 | Episode: 285 | Qmax: -7.6515 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 286 | Qmax: -7.9154 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 287 | Qmax: -7.8840 | Exploration: 0.019589 \n",
      "| Reward: -41 | Episode: 288 | Qmax: -7.6938 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 289 | Qmax: -7.9056 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 290 | Qmax: -7.8751 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 291 | Qmax: -7.9292 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 292 | Qmax: -7.7026 | Exploration: 0.019589 \n",
      "| Reward: -39 | Episode: 293 | Qmax: -7.4491 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 294 | Qmax: -7.7860 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 295 | Qmax: -7.5107 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 296 | Qmax: -7.5676 | Exploration: 0.019589 \n",
      "| Reward: -30 | Episode: 297 | Qmax: -7.5148 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 298 | Qmax: -7.6804 | Exploration: 0.019589 \n",
      "| Reward: -37 | Episode: 299 | Qmax: -7.5660 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -21 | Episode: 300 | Qmax: -7.7082 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 301 | Qmax: -7.8301 | Exploration: 0.019589 \n",
      "| Reward: -34 | Episode: 302 | Qmax: -7.5855 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 303 | Qmax: -7.8375 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 304 | Qmax: -7.8798 | Exploration: 0.019589 \n",
      "| Reward: -187 | Episode: 305 | Qmax: -7.5063 | Exploration: 0.019589 \n",
      "| Reward: -61 | Episode: 306 | Qmax: -7.4809 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 307 | Qmax: -7.9587 | Exploration: 0.019589 \n",
      "| Reward: -24 | Episode: 308 | Qmax: -7.6121 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 309 | Qmax: -7.9149 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 310 | Qmax: -7.8688 | Exploration: 0.019589 \n",
      "| Reward: -45 | Episode: 311 | Qmax: -7.3452 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 312 | Qmax: -7.6696 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 313 | Qmax: -7.6466 | Exploration: 0.019589 \n",
      "| Reward: -61 | Episode: 314 | Qmax: -7.3133 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 315 | Qmax: -7.6162 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 316 | Qmax: -7.6810 | Exploration: 0.019589 \n",
      "| Reward: -58 | Episode: 317 | Qmax: -7.2595 | Exploration: 0.019589 \n",
      "| Reward: -59 | Episode: 318 | Qmax: -7.3087 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 319 | Qmax: -7.6662 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 320 | Qmax: -7.7245 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 321 | Qmax: -7.7410 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 322 | Qmax: -7.5513 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 323 | Qmax: -7.7306 | Exploration: 0.019589 \n",
      "| Reward: -33 | Episode: 324 | Qmax: -7.5358 | Exploration: 0.019589 \n",
      "| Reward: -77 | Episode: 325 | Qmax: -7.4787 | Exploration: 0.019589 \n",
      "| Reward: -41 | Episode: 326 | Qmax: -7.5712 | Exploration: 0.019589 \n",
      "| Reward: -41 | Episode: 327 | Qmax: -7.6105 | Exploration: 0.019589 \n",
      "| Reward: -34 | Episode: 328 | Qmax: -7.4820 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 329 | Qmax: -7.8042 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 330 | Qmax: -7.6837 | Exploration: 0.019589 \n",
      "| Reward: -24 | Episode: 331 | Qmax: -7.7754 | Exploration: 0.019589 \n",
      "| Reward: -56 | Episode: 332 | Qmax: -7.4862 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 333 | Qmax: -7.6982 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 334 | Qmax: -7.5715 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 335 | Qmax: -7.6236 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 336 | Qmax: -7.8023 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 337 | Qmax: -7.8079 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 338 | Qmax: -7.5918 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 339 | Qmax: -7.9111 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 340 | Qmax: -7.7634 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 341 | Qmax: -7.8078 | Exploration: 0.019589 \n",
      "| Reward: -83 | Episode: 342 | Qmax: -7.2081 | Exploration: 0.019589 \n",
      "| Reward: -32 | Episode: 343 | Qmax: -7.1713 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 344 | Qmax: -7.4734 | Exploration: 0.019589 \n",
      "| Reward: -61 | Episode: 345 | Qmax: -7.0993 | Exploration: 0.019589 \n",
      "| Reward: -41 | Episode: 346 | Qmax: -7.2782 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 347 | Qmax: -7.4120 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 348 | Qmax: -7.5086 | Exploration: 0.019589 \n",
      "| Reward: -41 | Episode: 349 | Qmax: -7.4244 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -23 | Episode: 350 | Qmax: -7.6316 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 351 | Qmax: -7.6781 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 352 | Qmax: -7.8324 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 353 | Qmax: -7.7688 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 354 | Qmax: -7.7505 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 355 | Qmax: -7.7345 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 356 | Qmax: -7.4329 | Exploration: 0.019589 \n",
      "| Reward: -90 | Episode: 357 | Qmax: -7.1960 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 358 | Qmax: -7.5248 | Exploration: 0.019589 \n",
      "| Reward: -93 | Episode: 359 | Qmax: -7.2369 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -17 | Episode: 360 | Qmax: -7.4700 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 361 | Qmax: -7.4975 | Exploration: 0.019589 \n",
      "| Reward: -24 | Episode: 362 | Qmax: -7.3644 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 363 | Qmax: -7.5587 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 364 | Qmax: -7.6893 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 365 | Qmax: -7.6078 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 366 | Qmax: -7.4369 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 367 | Qmax: -7.5747 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 368 | Qmax: -7.4483 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 369 | Qmax: -7.3660 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 370 | Qmax: -7.3365 | Exploration: 0.019589 \n",
      "| Reward: -71 | Episode: 371 | Qmax: -7.2276 | Exploration: 0.019589 \n",
      "| Reward: -71 | Episode: 372 | Qmax: -7.2656 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 373 | Qmax: -7.4315 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 374 | Qmax: -7.2937 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 375 | Qmax: -7.5462 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 376 | Qmax: -7.4449 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 377 | Qmax: -7.2769 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 378 | Qmax: -7.4996 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 379 | Qmax: -7.3060 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 380 | Qmax: -7.5771 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 381 | Qmax: -7.6794 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 382 | Qmax: -7.3502 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 383 | Qmax: -7.6348 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 384 | Qmax: -7.5114 | Exploration: 0.019589 \n",
      "| Reward: -43 | Episode: 385 | Qmax: -7.3256 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 386 | Qmax: -7.6789 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 387 | Qmax: -7.4813 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 388 | Qmax: -7.5416 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 389 | Qmax: -7.4020 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 390 | Qmax: -7.5725 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 391 | Qmax: -7.3707 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 392 | Qmax: -7.5342 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 393 | Qmax: -7.7097 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 394 | Qmax: -7.5437 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 395 | Qmax: -7.6709 | Exploration: 0.019589 \n",
      "| Reward: -91 | Episode: 396 | Qmax: -7.1636 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 397 | Qmax: -7.3761 | Exploration: 0.019589 \n",
      "| Reward: -33 | Episode: 398 | Qmax: -7.3294 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 399 | Qmax: -7.5760 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -23 | Episode: 400 | Qmax: -7.4016 | Exploration: 0.019589 \n",
      "| Reward: -40 | Episode: 401 | Qmax: -7.0749 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 402 | Qmax: -7.3049 | Exploration: 0.019589 \n",
      "| Reward: -51 | Episode: 403 | Qmax: -7.1007 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 404 | Qmax: -7.5217 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 405 | Qmax: -7.6782 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 406 | Qmax: -7.5063 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 407 | Qmax: -7.4986 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 408 | Qmax: -7.5824 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 409 | Qmax: -7.5640 | Exploration: 0.019589 \n",
      "| Reward: -48 | Episode: 410 | Qmax: -7.3507 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 411 | Qmax: -7.6267 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 412 | Qmax: -7.6918 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 413 | Qmax: -7.7287 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 414 | Qmax: -7.6980 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 415 | Qmax: -7.7244 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 416 | Qmax: -7.7550 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 417 | Qmax: -7.4584 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 418 | Qmax: -7.6688 | Exploration: 0.019589 \n",
      "| Reward: -46 | Episode: 419 | Qmax: -7.3079 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 420 | Qmax: -7.7101 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 421 | Qmax: -7.6833 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 422 | Qmax: -7.6746 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 423 | Qmax: -7.4907 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 424 | Qmax: -7.7088 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 425 | Qmax: -7.6107 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 426 | Qmax: -7.6495 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 427 | Qmax: -7.6996 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 428 | Qmax: -7.5436 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 429 | Qmax: -7.3879 | Exploration: 0.019589 \n",
      "| Reward: -34 | Episode: 430 | Qmax: -7.0887 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 431 | Qmax: -7.4179 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 432 | Qmax: -7.2101 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 433 | Qmax: -7.3083 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 434 | Qmax: -7.2239 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 435 | Qmax: -7.2525 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 436 | Qmax: -7.3164 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 437 | Qmax: -7.0718 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 438 | Qmax: -7.1438 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 439 | Qmax: -7.2557 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 440 | Qmax: -7.2246 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 441 | Qmax: -7.0743 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 442 | Qmax: -6.8849 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 443 | Qmax: -6.9332 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 444 | Qmax: -6.9860 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 445 | Qmax: -6.9693 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 446 | Qmax: -6.9573 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 447 | Qmax: -7.1322 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 448 | Qmax: -7.0155 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 449 | Qmax: -7.1771 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 450 | Qmax: -6.9880 | Exploration: 0.019589 \n",
      "| Reward: -41 | Episode: 451 | Qmax: -6.7879 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 452 | Qmax: -7.2195 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 453 | Qmax: -7.0690 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 454 | Qmax: -7.1957 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 455 | Qmax: -7.2988 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 456 | Qmax: -7.2026 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 457 | Qmax: -7.2180 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 458 | Qmax: -7.2940 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 459 | Qmax: -7.0585 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -21 | Episode: 460 | Qmax: -7.1289 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 461 | Qmax: -7.2569 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 462 | Qmax: -6.9126 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 463 | Qmax: -6.7649 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 464 | Qmax: -7.0824 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 465 | Qmax: -7.0653 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 466 | Qmax: -6.9034 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -15 | Episode: 467 | Qmax: -7.2082 | Exploration: 0.019589 \n",
      "| Reward: -111 | Episode: 468 | Qmax: -6.7739 | Exploration: 0.019589 \n",
      "| Reward: -37 | Episode: 469 | Qmax: -6.8584 | Exploration: 0.019589 \n",
      "| Reward: -90 | Episode: 470 | Qmax: -6.8048 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 471 | Qmax: -7.2039 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 472 | Qmax: -7.2074 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 473 | Qmax: -7.3614 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 474 | Qmax: -7.1585 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 475 | Qmax: -7.1032 | Exploration: 0.019589 \n",
      "| Reward: -28 | Episode: 476 | Qmax: -6.8701 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 477 | Qmax: -7.0271 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 478 | Qmax: -6.8595 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 479 | Qmax: -6.9389 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 480 | Qmax: -6.9404 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 481 | Qmax: -6.9474 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 482 | Qmax: -6.8320 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 483 | Qmax: -6.9022 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 484 | Qmax: -6.8675 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 485 | Qmax: -6.8767 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 486 | Qmax: -6.8919 | Exploration: 0.019589 \n",
      "| Reward: -73 | Episode: 487 | Qmax: -6.4703 | Exploration: 0.019589 \n",
      "| Reward: -24 | Episode: 488 | Qmax: -6.5940 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 489 | Qmax: -7.0494 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 490 | Qmax: -6.8143 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 491 | Qmax: -6.8992 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 492 | Qmax: -6.7491 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 493 | Qmax: -6.8128 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 494 | Qmax: -6.8520 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 495 | Qmax: -6.7742 | Exploration: 0.019589 \n",
      "| Reward: -77 | Episode: 496 | Qmax: -6.4028 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 497 | Qmax: -6.7895 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 498 | Qmax: -6.8963 | Exploration: 0.019589 \n",
      "| Reward: -139 | Episode: 499 | Qmax: -6.5265 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 500 | Qmax: -6.8928 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 501 | Qmax: -6.8685 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 502 | Qmax: -6.8622 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 503 | Qmax: -6.9019 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 504 | Qmax: -6.9857 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 505 | Qmax: -7.1635 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 506 | Qmax: -7.1534 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 507 | Qmax: -7.2105 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 508 | Qmax: -7.2861 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 509 | Qmax: -7.2893 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 510 | Qmax: -7.0718 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 511 | Qmax: -7.1409 | Exploration: 0.019589 \n",
      "| Reward: -45 | Episode: 512 | Qmax: -6.9286 | Exploration: 0.019589 \n",
      "| Reward: -391 | Episode: 513 | Qmax: -6.6860 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 514 | Qmax: -6.7647 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 515 | Qmax: -7.0290 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 516 | Qmax: -7.0016 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 517 | Qmax: -6.7981 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 518 | Qmax: -6.8413 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 519 | Qmax: -6.8932 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 520 | Qmax: -6.8882 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 521 | Qmax: -6.9913 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 522 | Qmax: -6.7673 | Exploration: 0.019589 \n",
      "| Reward: -92 | Episode: 523 | Qmax: -6.6416 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 524 | Qmax: -6.8282 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 525 | Qmax: -6.7260 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 526 | Qmax: -6.6799 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 527 | Qmax: -6.9235 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 528 | Qmax: -6.7184 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 529 | Qmax: -6.8800 | Exploration: 0.019589 \n",
      "| Reward: -52 | Episode: 530 | Qmax: -6.6418 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 531 | Qmax: -7.0027 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 532 | Qmax: -6.9686 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 533 | Qmax: -7.0288 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 534 | Qmax: -7.0211 | Exploration: 0.019589 \n",
      "| Reward: -114 | Episode: 535 | Qmax: -6.5376 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 536 | Qmax: -6.7881 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 537 | Qmax: -6.6401 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 538 | Qmax: -6.8495 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 539 | Qmax: -6.7906 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 540 | Qmax: -6.8278 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 541 | Qmax: -6.6709 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 542 | Qmax: -6.6378 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 543 | Qmax: -6.7183 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 544 | Qmax: -6.5233 | Exploration: 0.019589 \n",
      "| Reward: -55 | Episode: 545 | Qmax: -6.3148 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 546 | Qmax: -6.6263 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 547 | Qmax: -6.5885 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 548 | Qmax: -6.5855 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 549 | Qmax: -6.2727 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 550 | Qmax: -6.4190 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 551 | Qmax: -6.2898 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 552 | Qmax: -6.3510 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 553 | Qmax: -6.3536 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 554 | Qmax: -6.3030 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 555 | Qmax: -6.4127 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 556 | Qmax: -6.4284 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 557 | Qmax: -6.4004 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 558 | Qmax: -6.6111 | Exploration: 0.019589 \n",
      "| Reward: -311 | Episode: 559 | Qmax: -6.1165 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 560 | Qmax: -6.5135 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 561 | Qmax: -6.4104 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 562 | Qmax: -6.4123 | Exploration: 0.019589 \n",
      "| Reward: -38 | Episode: 563 | Qmax: -6.3119 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 564 | Qmax: -6.6141 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 565 | Qmax: -6.5335 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 566 | Qmax: -6.4193 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 567 | Qmax: -6.5974 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 568 | Qmax: -6.6657 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 569 | Qmax: -6.4980 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 570 | Qmax: -6.3817 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 571 | Qmax: -6.5011 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 572 | Qmax: -6.6214 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 573 | Qmax: -6.4860 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 574 | Qmax: -6.6398 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 575 | Qmax: -6.7016 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 576 | Qmax: -6.4889 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 577 | Qmax: -6.4621 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 578 | Qmax: -6.3808 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 579 | Qmax: -6.6319 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -25 | Episode: 580 | Qmax: -6.3684 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 581 | Qmax: -6.6124 | Exploration: 0.019589 \n",
      "| Reward: -108 | Episode: 582 | Qmax: -6.2653 | Exploration: 0.019589 \n",
      "| Reward: -43 | Episode: 583 | Qmax: -6.4446 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -15 | Episode: 584 | Qmax: -6.5964 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 585 | Qmax: -6.7205 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 586 | Qmax: -6.7476 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 587 | Qmax: -6.6316 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 588 | Qmax: -6.3729 | Exploration: 0.019589 \n",
      "| Reward: -39 | Episode: 589 | Qmax: -6.4025 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 590 | Qmax: -6.7132 | Exploration: 0.019589 \n",
      "| Reward: -83 | Episode: 591 | Qmax: -6.4090 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 592 | Qmax: -6.8321 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 593 | Qmax: -6.9993 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 594 | Qmax: -6.8893 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 595 | Qmax: -7.2137 | Exploration: 0.019589 \n",
      "| Reward: -126 | Episode: 596 | Qmax: -6.5028 | Exploration: 0.019589 \n",
      "| Reward: -39 | Episode: 597 | Qmax: -6.4712 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 598 | Qmax: -6.6426 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 599 | Qmax: -6.6000 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -17 | Episode: 600 | Qmax: -6.4549 | Exploration: 0.019589 \n",
      "| Reward: -38 | Episode: 601 | Qmax: -6.3433 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 602 | Qmax: -6.5172 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 603 | Qmax: -6.5910 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 604 | Qmax: -6.4857 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 605 | Qmax: -6.6534 | Exploration: 0.019589 \n",
      "| Reward: -80 | Episode: 606 | Qmax: -6.2379 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 607 | Qmax: -6.5750 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 608 | Qmax: -6.3713 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 609 | Qmax: -6.5303 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 610 | Qmax: -6.6324 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 611 | Qmax: -6.5579 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 612 | Qmax: -6.6148 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 613 | Qmax: -6.5123 | Exploration: 0.019589 \n",
      "| Reward: -194 | Episode: 614 | Qmax: -6.1809 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 615 | Qmax: -6.4345 | Exploration: 0.019589 \n",
      "| Reward: -40 | Episode: 616 | Qmax: -6.1653 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 617 | Qmax: -6.2677 | Exploration: 0.019589 \n",
      "| Reward: -103 | Episode: 618 | Qmax: -6.0940 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 619 | Qmax: -6.5823 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -23 | Episode: 620 | Qmax: -6.4413 | Exploration: 0.019589 \n",
      "| Reward: -35 | Episode: 621 | Qmax: -6.4459 | Exploration: 0.019589 \n",
      "| Reward: -28 | Episode: 622 | Qmax: -6.4674 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 623 | Qmax: -6.6445 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 624 | Qmax: -6.7651 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 625 | Qmax: -6.6613 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 626 | Qmax: -6.6970 | Exploration: 0.019589 \n",
      "| Reward: -208 | Episode: 627 | Qmax: -6.2745 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 628 | Qmax: -6.6970 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 629 | Qmax: -6.5701 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 630 | Qmax: -6.4776 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 631 | Qmax: -6.5459 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 632 | Qmax: -6.3528 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 633 | Qmax: -6.4311 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 634 | Qmax: -6.4941 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 635 | Qmax: -6.5484 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 636 | Qmax: -6.5439 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 637 | Qmax: -6.4704 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 638 | Qmax: -6.5585 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 639 | Qmax: -6.3399 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 640 | Qmax: -6.5792 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 641 | Qmax: -6.4841 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 642 | Qmax: -6.5178 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 643 | Qmax: -6.6356 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 644 | Qmax: -6.6439 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 645 | Qmax: -6.5484 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 646 | Qmax: -6.6439 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 647 | Qmax: -6.6251 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 648 | Qmax: -6.6049 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 649 | Qmax: -6.5327 | Exploration: 0.019589 \n",
      "| Reward: -55 | Episode: 650 | Qmax: -6.4368 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 651 | Qmax: -6.6051 | Exploration: 0.019589 \n",
      "| Reward: -73 | Episode: 652 | Qmax: -6.4306 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 653 | Qmax: -6.6086 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 654 | Qmax: -6.7102 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 655 | Qmax: -6.6842 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 656 | Qmax: -6.5567 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 657 | Qmax: -6.7520 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 658 | Qmax: -6.5641 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 659 | Qmax: -6.6619 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 660 | Qmax: -6.8599 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 661 | Qmax: -6.7250 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 662 | Qmax: -6.7084 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 663 | Qmax: -6.8147 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 664 | Qmax: -6.8613 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 665 | Qmax: -6.8102 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 666 | Qmax: -6.7333 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 667 | Qmax: -6.9007 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 668 | Qmax: -6.7202 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 669 | Qmax: -6.8778 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 670 | Qmax: -6.9303 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 671 | Qmax: -6.7932 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 672 | Qmax: -6.7802 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 673 | Qmax: -6.8617 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 674 | Qmax: -6.7522 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 675 | Qmax: -6.6908 | Exploration: 0.019589 \n",
      "| Reward: -28 | Episode: 676 | Qmax: -6.6481 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 677 | Qmax: -6.7308 | Exploration: 0.019589 \n",
      "| Reward: -22 | Episode: 678 | Qmax: -6.6212 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 679 | Qmax: -6.7863 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -21 | Episode: 680 | Qmax: -6.7343 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 681 | Qmax: -6.7035 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 682 | Qmax: -6.7523 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 683 | Qmax: -6.8154 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 684 | Qmax: -6.7643 | Exploration: 0.019589 \n",
      "| Reward: -48 | Episode: 685 | Qmax: -6.6034 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 686 | Qmax: -6.8609 | Exploration: 0.019589 \n",
      "| Reward: -28 | Episode: 687 | Qmax: -6.7140 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 688 | Qmax: -6.8642 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 689 | Qmax: -6.9678 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 690 | Qmax: -7.0439 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 691 | Qmax: -6.9588 | Exploration: 0.019589 \n",
      "| Reward: -406 | Episode: 692 | Qmax: -6.3168 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 693 | Qmax: -6.3607 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 694 | Qmax: -6.4227 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 695 | Qmax: -6.6122 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 696 | Qmax: -6.7073 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 697 | Qmax: -6.7318 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 698 | Qmax: -6.6185 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 699 | Qmax: -6.7000 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -20 | Episode: 700 | Qmax: -6.6048 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -15 | Episode: 701 | Qmax: -6.6095 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 702 | Qmax: -6.6505 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 703 | Qmax: -6.5921 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 704 | Qmax: -6.6226 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 705 | Qmax: -6.5503 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 706 | Qmax: -6.5722 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 707 | Qmax: -6.5787 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 708 | Qmax: -6.8002 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 709 | Qmax: -6.7233 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 710 | Qmax: -6.7112 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 711 | Qmax: -6.4634 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 712 | Qmax: -6.7898 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 713 | Qmax: -6.5999 | Exploration: 0.019589 \n",
      "| Reward: -37 | Episode: 714 | Qmax: -6.4840 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 715 | Qmax: -6.7972 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 716 | Qmax: -6.7547 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 717 | Qmax: -6.8935 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 718 | Qmax: -6.6967 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 719 | Qmax: -6.6900 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 720 | Qmax: -6.7579 | Exploration: 0.019589 \n",
      "| Reward: -40 | Episode: 721 | Qmax: -6.4481 | Exploration: 0.019589 \n",
      "| Reward: -77 | Episode: 722 | Qmax: -6.3429 | Exploration: 0.019589 \n",
      "| Reward: -29 | Episode: 723 | Qmax: -6.3633 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 724 | Qmax: -6.5895 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 725 | Qmax: -6.4804 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 726 | Qmax: -6.5871 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 727 | Qmax: -6.5588 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 728 | Qmax: -6.5474 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 729 | Qmax: -6.4630 | Exploration: 0.019589 \n",
      "| Reward: -60 | Episode: 730 | Qmax: -6.2726 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 731 | Qmax: -6.3974 | Exploration: 0.019589 \n",
      "| Reward: -27 | Episode: 732 | Qmax: -6.4104 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 733 | Qmax: -6.5259 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 734 | Qmax: -6.5565 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 735 | Qmax: -6.6086 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 736 | Qmax: -6.5798 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 737 | Qmax: -6.5656 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 738 | Qmax: -6.5410 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 739 | Qmax: -6.3785 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 740 | Qmax: -6.3030 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 741 | Qmax: -6.5226 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 742 | Qmax: -6.4567 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 743 | Qmax: -6.4153 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 744 | Qmax: -6.3436 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 745 | Qmax: -6.5265 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 746 | Qmax: -6.3980 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 747 | Qmax: -6.4857 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 748 | Qmax: -6.2560 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 749 | Qmax: -6.6014 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 750 | Qmax: -6.3733 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 751 | Qmax: -6.5120 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 752 | Qmax: -6.4185 | Exploration: 0.019589 \n",
      "| Reward: -22 | Episode: 753 | Qmax: -6.2523 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 754 | Qmax: -6.4709 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 755 | Qmax: -6.3315 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 756 | Qmax: -6.4262 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 757 | Qmax: -6.3762 | Exploration: 0.019589 \n",
      "| Reward: -22 | Episode: 758 | Qmax: -6.2972 | Exploration: 0.019589 \n",
      "| Reward: -22 | Episode: 759 | Qmax: -6.3332 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -17 | Episode: 760 | Qmax: -6.4177 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 761 | Qmax: -6.2416 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 762 | Qmax: -6.5417 | Exploration: 0.019589 \n",
      "| Reward: -31 | Episode: 763 | Qmax: -6.3011 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 764 | Qmax: -6.3823 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 765 | Qmax: -6.5670 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 766 | Qmax: -6.5767 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 767 | Qmax: -6.4525 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 768 | Qmax: -6.7841 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 769 | Qmax: -6.5121 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 770 | Qmax: -6.5555 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 771 | Qmax: -6.5261 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 772 | Qmax: -6.5871 | Exploration: 0.019589 \n",
      "| Reward: -24 | Episode: 773 | Qmax: -6.5309 | Exploration: 0.019589 \n",
      "| Reward: -26 | Episode: 774 | Qmax: -6.6147 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 775 | Qmax: -6.9202 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 776 | Qmax: -6.9512 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 777 | Qmax: -6.6962 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 778 | Qmax: -6.8547 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 779 | Qmax: -6.6279 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 780 | Qmax: -6.7376 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 781 | Qmax: -6.7536 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 782 | Qmax: -6.7383 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 783 | Qmax: -6.6436 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 784 | Qmax: -6.6870 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 785 | Qmax: -6.6664 | Exploration: 0.019589 \n",
      "| Reward: -23 | Episode: 786 | Qmax: -6.5155 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 787 | Qmax: -6.5463 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 788 | Qmax: -6.5684 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 789 | Qmax: -6.4746 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 790 | Qmax: -6.5574 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 791 | Qmax: -6.3656 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 792 | Qmax: -6.4755 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 793 | Qmax: -6.6511 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 794 | Qmax: -6.5717 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 795 | Qmax: -6.5940 | Exploration: 0.019589 \n",
      "| Reward: -22 | Episode: 796 | Qmax: -6.4616 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 797 | Qmax: -6.6654 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 798 | Qmax: -6.5789 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 799 | Qmax: -6.5466 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 800 | Qmax: -6.6482 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 801 | Qmax: -6.5142 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 802 | Qmax: -6.4731 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 803 | Qmax: -6.4667 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 804 | Qmax: -6.6195 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 805 | Qmax: -6.4347 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 806 | Qmax: -6.4824 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 807 | Qmax: -6.5315 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 808 | Qmax: -6.4845 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 809 | Qmax: -6.5103 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 810 | Qmax: -6.2427 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 811 | Qmax: -6.4063 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 812 | Qmax: -6.3366 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 813 | Qmax: -6.3669 | Exploration: 0.019589 \n",
      "| Reward: -50 | Episode: 814 | Qmax: -6.2207 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 815 | Qmax: -6.3109 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 816 | Qmax: -6.5670 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 817 | Qmax: -6.2461 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -34 | Episode: 818 | Qmax: -6.1198 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 819 | Qmax: -6.4567 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 820 | Qmax: -6.3643 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 821 | Qmax: -6.4849 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 822 | Qmax: -6.4583 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 823 | Qmax: -6.1235 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 824 | Qmax: -6.2423 | Exploration: 0.019589 \n",
      "| Reward: -39 | Episode: 825 | Qmax: -6.1386 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 826 | Qmax: -6.2672 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 827 | Qmax: -6.3666 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 828 | Qmax: -6.4367 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 829 | Qmax: -6.3791 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 830 | Qmax: -6.4052 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 831 | Qmax: -6.2597 | Exploration: 0.019589 \n",
      "| Reward: -25 | Episode: 832 | Qmax: -6.4009 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 833 | Qmax: -6.4950 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 834 | Qmax: -6.5105 | Exploration: 0.019589 \n",
      "| Reward: -39 | Episode: 835 | Qmax: -6.1840 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 836 | Qmax: -6.5213 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 837 | Qmax: -6.5089 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 838 | Qmax: -6.6415 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 839 | Qmax: -6.8361 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -20 | Episode: 840 | Qmax: -6.4241 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 841 | Qmax: -6.4035 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 842 | Qmax: -6.4855 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 843 | Qmax: -6.6649 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 844 | Qmax: -6.5310 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 845 | Qmax: -6.4308 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 846 | Qmax: -6.5759 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 847 | Qmax: -6.6618 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 848 | Qmax: -6.4646 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 849 | Qmax: -6.4656 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 850 | Qmax: -6.3375 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 851 | Qmax: -6.3442 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 852 | Qmax: -6.3933 | Exploration: 0.019589 \n",
      "| Reward: -151 | Episode: 853 | Qmax: -6.1125 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 854 | Qmax: -6.6228 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 855 | Qmax: -6.7319 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 856 | Qmax: -6.5284 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 857 | Qmax: -6.5867 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 858 | Qmax: -6.8425 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 859 | Qmax: -6.6761 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -16 | Episode: 860 | Qmax: -6.4841 | Exploration: 0.019589 \n",
      "| Reward: -22 | Episode: 861 | Qmax: -6.5696 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 862 | Qmax: -6.4198 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 863 | Qmax: -6.6128 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 864 | Qmax: -6.5743 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 865 | Qmax: -6.5563 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 866 | Qmax: -6.4829 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 867 | Qmax: -6.5510 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 868 | Qmax: -6.5107 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 869 | Qmax: -6.6268 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 870 | Qmax: -6.5574 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 871 | Qmax: -6.5983 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 872 | Qmax: -6.6438 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 873 | Qmax: -6.4527 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 874 | Qmax: -6.5532 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 875 | Qmax: -6.5265 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 876 | Qmax: -6.5000 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 877 | Qmax: -6.6284 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 878 | Qmax: -6.5800 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 879 | Qmax: -6.4255 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 880 | Qmax: -6.6989 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 881 | Qmax: -6.5422 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 882 | Qmax: -6.4706 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 883 | Qmax: -6.2772 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 884 | Qmax: -6.3430 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 885 | Qmax: -6.3288 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 886 | Qmax: -6.5099 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 887 | Qmax: -6.3490 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 888 | Qmax: -6.2007 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 889 | Qmax: -6.5853 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 890 | Qmax: -6.4412 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 891 | Qmax: -6.4213 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 892 | Qmax: -6.4797 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 893 | Qmax: -6.6092 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 894 | Qmax: -6.5449 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 895 | Qmax: -6.2105 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 896 | Qmax: -6.2824 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 897 | Qmax: -6.4288 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 898 | Qmax: -6.4360 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 899 | Qmax: -6.3545 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 900 | Qmax: -6.3950 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 901 | Qmax: -6.4308 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 902 | Qmax: -6.5444 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 903 | Qmax: -6.5564 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 904 | Qmax: -6.2877 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 905 | Qmax: -6.4035 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 906 | Qmax: -6.3192 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 907 | Qmax: -6.2422 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 908 | Qmax: -6.4216 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 909 | Qmax: -6.3794 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 910 | Qmax: -6.5702 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 911 | Qmax: -6.3686 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 912 | Qmax: -6.4358 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 913 | Qmax: -6.3380 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 914 | Qmax: -6.3245 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 915 | Qmax: -6.4646 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 916 | Qmax: -6.3512 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 917 | Qmax: -6.5348 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 918 | Qmax: -6.2852 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 919 | Qmax: -6.3922 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -17 | Episode: 920 | Qmax: -6.3880 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 921 | Qmax: -6.4007 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 922 | Qmax: -6.4443 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 923 | Qmax: -6.5582 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 924 | Qmax: -6.4708 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 925 | Qmax: -6.5428 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 926 | Qmax: -6.5461 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 927 | Qmax: -6.3880 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 928 | Qmax: -6.5039 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 929 | Qmax: -6.5003 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 930 | Qmax: -6.4613 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 931 | Qmax: -6.4471 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 932 | Qmax: -6.3541 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 933 | Qmax: -6.4084 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 934 | Qmax: -6.4312 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -15 | Episode: 935 | Qmax: -6.4557 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 936 | Qmax: -6.4773 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 937 | Qmax: -6.7384 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 938 | Qmax: -6.5745 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 939 | Qmax: -6.7488 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 940 | Qmax: -6.7465 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 941 | Qmax: -6.7463 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 942 | Qmax: -6.5387 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 943 | Qmax: -6.4686 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 944 | Qmax: -6.4836 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 945 | Qmax: -6.6085 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 946 | Qmax: -6.6487 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 947 | Qmax: -6.7580 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 948 | Qmax: -6.3794 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 949 | Qmax: -6.5933 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 950 | Qmax: -6.4253 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 951 | Qmax: -6.5734 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 952 | Qmax: -6.3338 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 953 | Qmax: -6.4480 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 954 | Qmax: -6.7509 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 955 | Qmax: -6.2757 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 956 | Qmax: -6.6864 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 957 | Qmax: -6.1050 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 958 | Qmax: -6.4597 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 959 | Qmax: -6.6747 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 960 | Qmax: -6.3520 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 961 | Qmax: -6.3937 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 962 | Qmax: -6.6135 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 963 | Qmax: -6.5412 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 964 | Qmax: -6.3357 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 965 | Qmax: -6.1049 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 966 | Qmax: -6.3183 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 967 | Qmax: -6.4994 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 968 | Qmax: -6.4095 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 969 | Qmax: -6.4861 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 970 | Qmax: -6.4305 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 971 | Qmax: -6.5336 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 972 | Qmax: -6.4844 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 973 | Qmax: -6.4553 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 974 | Qmax: -6.5878 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 975 | Qmax: -6.5578 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 976 | Qmax: -6.4198 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 977 | Qmax: -6.5179 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 978 | Qmax: -6.3813 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 979 | Qmax: -6.4862 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -17 | Episode: 980 | Qmax: -6.5100 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 981 | Qmax: -6.4118 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 982 | Qmax: -6.5290 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 983 | Qmax: -6.4435 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 984 | Qmax: -6.7624 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 985 | Qmax: -6.5613 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 986 | Qmax: -6.6474 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 987 | Qmax: -6.6519 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 988 | Qmax: -7.2320 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 989 | Qmax: -6.6405 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 990 | Qmax: -7.1222 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 991 | Qmax: -7.3209 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 992 | Qmax: -7.1713 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 993 | Qmax: -7.2515 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 994 | Qmax: -7.2796 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 995 | Qmax: -7.3371 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 996 | Qmax: -7.4176 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 997 | Qmax: -7.7105 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 998 | Qmax: -7.2375 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 999 | Qmax: -7.0422 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 1000 | Qmax: -7.4187 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1001 | Qmax: -7.6174 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1002 | Qmax: -7.5068 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1003 | Qmax: -7.5638 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 1004 | Qmax: -7.4885 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1005 | Qmax: -7.4797 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1006 | Qmax: -7.4374 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1007 | Qmax: -7.6371 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 1008 | Qmax: -7.1973 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1009 | Qmax: -7.4782 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1010 | Qmax: -7.1862 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1011 | Qmax: -7.3813 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1012 | Qmax: -7.5486 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 1013 | Qmax: -7.3797 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1014 | Qmax: -7.2127 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1015 | Qmax: -7.5806 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1016 | Qmax: -7.4800 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1017 | Qmax: -7.1244 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1018 | Qmax: -7.5610 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1019 | Qmax: -7.0457 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 1020 | Qmax: -6.2301 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 1021 | Qmax: -7.0689 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1022 | Qmax: -7.0314 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1023 | Qmax: -6.1661 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1024 | Qmax: -7.4873 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 1025 | Qmax: -6.8437 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 1026 | Qmax: -6.8609 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 1027 | Qmax: -6.9675 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1028 | Qmax: -6.1433 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 1029 | Qmax: -6.5402 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1030 | Qmax: -7.2699 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 1031 | Qmax: -6.2208 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1032 | Qmax: -6.9655 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 1033 | Qmax: -7.5655 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 1034 | Qmax: -6.6557 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1035 | Qmax: -6.9610 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1036 | Qmax: -6.9446 | Exploration: 0.019589 \n",
      "| Reward: -21 | Episode: 1037 | Qmax: -6.3843 | Exploration: 0.019589 \n",
      "| Reward: -18 | Episode: 1038 | Qmax: -6.5205 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1039 | Qmax: -7.6631 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -23 | Episode: 1040 | Qmax: -6.6151 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 1041 | Qmax: -6.7368 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1042 | Qmax: -6.4081 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 1043 | Qmax: -7.3662 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1044 | Qmax: -6.0082 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1045 | Qmax: -6.8325 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1046 | Qmax: -6.5008 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 1047 | Qmax: -6.7720 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1048 | Qmax: -6.7271 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1049 | Qmax: -6.9611 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 1050 | Qmax: -6.9429 | Exploration: 0.019589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -19 | Episode: 1051 | Qmax: -6.6962 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 1052 | Qmax: -6.8901 | Exploration: 0.019589 \n",
      "| Reward: -16 | Episode: 1053 | Qmax: -6.4211 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 1054 | Qmax: -6.2812 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1055 | Qmax: -7.0855 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1056 | Qmax: -7.0393 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1057 | Qmax: -6.4473 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1058 | Qmax: -6.8326 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1059 | Qmax: -6.2564 | Exploration: 0.019589 \n",
      "DDQN Saved\n",
      "| Reward: -15 | Episode: 1060 | Qmax: -6.2245 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1061 | Qmax: -6.0386 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1062 | Qmax: -6.2417 | Exploration: 0.019589 \n",
      "| Reward: -19 | Episode: 1063 | Qmax: -6.7952 | Exploration: 0.019589 \n",
      "| Reward: -17 | Episode: 1064 | Qmax: -6.2680 | Exploration: 0.019589 \n",
      "| Reward: -20 | Episode: 1065 | Qmax: -5.7057 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1066 | Qmax: -6.2920 | Exploration: 0.019589 \n",
      "| Reward: -24 | Episode: 1067 | Qmax: -5.2454 | Exploration: 0.019589 \n",
      "| Reward: -15 | Episode: 1068 | Qmax: -6.8454 | Exploration: 0.019589 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-33c3870d1fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mQnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTAU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMINIBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-2c25c1efa8de>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sess, env, qnet)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mstate_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/DDQN/qnetwork.py\u001b[0m in \u001b[0;36mpredict_q\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    env = CurrentWorld()\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    env.seed(RANDOM_SEED)\n",
    "    \n",
    "    state_dim = 2\n",
    "    action_dim = 5\n",
    "    \n",
    "    Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR)\n",
    "    \n",
    "    train(sess, env, Qnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "world = np.zeros(env.shape)\n",
    "a_list = []\n",
    "s_list = []\n",
    "for s in range(env.nS):\n",
    "    a_list += [np.argmax(P[s])]\n",
    "    s_list += [np.unravel_index(s,env.shape)]\n",
    "for s,a in zip(s_list,a_list):\n",
    "    world[s] = a\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib auto\n",
    "plt.imshow(world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "plotting.plot_episode_stats(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def get_optimal_path(Q,env):\n",
    "    env.reset()\n",
    "    start_state = env.start_state\n",
    "    terminal_state = env.terminal_state\n",
    "    state = np.ravel_multi_index(start_state,env.shape)\n",
    "    path = [start_state]\n",
    "    value = 0\n",
    "    action = []\n",
    "    while 1:\n",
    "        next_action = np.argmax(Q[state])\n",
    "        next_state,reward,done,_ = env.step(next_action)\n",
    "        path += [np.unravel_index(next_state,env.shape)]\n",
    "        value += reward\n",
    "        action += [next_action]\n",
    "        if done:\n",
    "            return path, action, value\n",
    "            break\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opt_path,action,value = get_optimal_path(Q,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%matplotlib auto\n",
    "world = deepcopy(env.winds)\n",
    "t = 0\n",
    "for i in opt_path[:-1]:\n",
    "    world[i] = 6\n",
    "#     world[i] += action[t]\n",
    "    t+=1\n",
    "plt.imshow(world)\n",
    "# print value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
